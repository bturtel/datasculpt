{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "Core Features\n",
    "- [x] Handle missing values in structured outputs\n",
    "- [x] Test other APIs - use env variables in yaml\n",
    "- [ ] Consider shipping JUST the sculptors as a library\n",
    "- [ ] Why is it making up fields when I use Deepinfra?\n",
    "\n",
    "Helper Improvements - maybe ship separately\n",
    "- [ ] Test helpers for datasources\n",
    "- [ ] String together steps\n",
    "- [ ] Clean up visualizer\n",
    "- [ ] Delete extra files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test FULL PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items: 100%|██████████| 20/20 [00:13<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to 6 items\n",
      "\n",
      "Step 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items: 100%|██████████| 6/6 [00:18<00:00,  3.01s/it]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/ai_therapy_out.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREDDIT_USER_AGENT\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m secrets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreddit\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_agent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     15\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m SculptorPipeline\u001b[38;5;241m.\u001b[39mfrom_config(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexamples/ai_therapy.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/datasculpt/sculptor/sculptor_pipeline.py:132\u001b[0m, in \u001b[0;36mSculptorPipeline.process_from_config\u001b[0;34m(self, n_workers, show_progress)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# Save if output configured\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_config:\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    133\u001b[0m         json\u001b[38;5;241m.\u001b[39mdump(results, f)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/ai_therapy_out.csv'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import toml\n",
    "from sculptor import SculptorPipeline\n",
    "\n",
    "secrets = toml.load(\"secrets.toml\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = secrets[\"openai\"][\"api_key\"]\n",
    "os.environ[\"DEEPINFRA_API_KEY\"] = secrets[\"deepinfra\"][\"api_key\"]\n",
    "os.environ[\"REDDIT_CLIENT_ID\"] = secrets[\"reddit\"][\"client_id\"]\n",
    "os.environ[\"REDDIT_CLIENT_SECRET\"] = secrets[\"reddit\"][\"client_secret\"]\n",
    "os.environ[\"REDDIT_USER_AGENT\"] = secrets[\"reddit\"][\"user_agent\"]\n",
    "\n",
    "pipeline = SculptorPipeline.from_config('examples/ai_therapy.yaml')\n",
    "results = pipeline.process_from_config(n_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on people.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import toml\n",
    "\n",
    "secrets = toml.load(\"secrets.toml\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = secrets[\"openai\"][\"api_key\"]\n",
    "os.environ[\"DEEPINFRA_API_KEY\"] = secrets[\"deepinfra\"][\"api_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items: 100%|██████████| 11/11 [00:02<00:00,  4.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to 8 items\n",
      "\n",
      "Step 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items: 100%|██████████| 8/8 [00:02<00:00,  3.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid_sample</th>\n",
       "      <th>explanation</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "      <th>occupation</th>\n",
       "      <th>interests</th>\n",
       "      <th>is_married</th>\n",
       "      <th>num_children</th>\n",
       "      <th>net_worth</th>\n",
       "      <th>first_letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice is 30 years old, lives in New York, and ...</td>\n",
       "      <td>True</td>\n",
       "      <td>The text contains detailed information about a...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>30</td>\n",
       "      <td>New York</td>\n",
       "      <td>software engineer</td>\n",
       "      <td>[hiking, reading]</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob, 25, is a teacher in London. He's an avid ...</td>\n",
       "      <td>True</td>\n",
       "      <td>The text contains information about a person n...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>25</td>\n",
       "      <td>London</td>\n",
       "      <td>teacher</td>\n",
       "      <td>[cycling]</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie is a 40-year-old data scientist from C...</td>\n",
       "      <td>True</td>\n",
       "      <td>The text contains information about a person n...</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>40</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>[skiing, cooking, photography]</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David, a 35-year-old architect, resides in San...</td>\n",
       "      <td>True</td>\n",
       "      <td>The text contains information about a person n...</td>\n",
       "      <td>David</td>\n",
       "      <td>35</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>architect</td>\n",
       "      <td>[rock climbing]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emily is a 28-year-old nurse in Seattle. She l...</td>\n",
       "      <td>True</td>\n",
       "      <td>The text contains information about a person n...</td>\n",
       "      <td>Emily</td>\n",
       "      <td>28</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>nurse</td>\n",
       "      <td>[traveling, trying new foods]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Frank is a 50-year-old lawyer living in Boston...</td>\n",
       "      <td>True</td>\n",
       "      <td>The text contains information about a person n...</td>\n",
       "      <td>Frank</td>\n",
       "      <td>50</td>\n",
       "      <td>Boston</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>[golfing, fishing]</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Grace, a 22-year-old student in Austin, is pas...</td>\n",
       "      <td>True</td>\n",
       "      <td>The text contains information about a person n...</td>\n",
       "      <td>Grace</td>\n",
       "      <td>22</td>\n",
       "      <td>Austin</td>\n",
       "      <td>student</td>\n",
       "      <td>[music, volunteering]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Katrina, a 28-year-old art expert in NYC.</td>\n",
       "      <td>True</td>\n",
       "      <td>The text contains information about a person n...</td>\n",
       "      <td>Katrina</td>\n",
       "      <td>28</td>\n",
       "      <td>NYC</td>\n",
       "      <td>art expert</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_valid_sample  \\\n",
       "0  Alice is 30 years old, lives in New York, and ...             True   \n",
       "1  Bob, 25, is a teacher in London. He's an avid ...             True   \n",
       "2  Charlie is a 40-year-old data scientist from C...             True   \n",
       "3  David, a 35-year-old architect, resides in San...             True   \n",
       "4  Emily is a 28-year-old nurse in Seattle. She l...             True   \n",
       "5  Frank is a 50-year-old lawyer living in Boston...             True   \n",
       "6  Grace, a 22-year-old student in Austin, is pas...             True   \n",
       "7          Katrina, a 28-year-old art expert in NYC.             True   \n",
       "\n",
       "                                         explanation     name  age  \\\n",
       "0  The text contains detailed information about a...    Alice   30   \n",
       "1  The text contains information about a person n...      Bob   25   \n",
       "2  The text contains information about a person n...  Charlie   40   \n",
       "3  The text contains information about a person n...    David   35   \n",
       "4  The text contains information about a person n...    Emily   28   \n",
       "5  The text contains information about a person n...    Frank   50   \n",
       "6  The text contains information about a person n...    Grace   22   \n",
       "7  The text contains information about a person n...  Katrina   28   \n",
       "\n",
       "            city         occupation                       interests  \\\n",
       "0       New York  software engineer               [hiking, reading]   \n",
       "1         London            teacher                       [cycling]   \n",
       "2        Chicago     data scientist  [skiing, cooking, photography]   \n",
       "3  San Francisco          architect                 [rock climbing]   \n",
       "4        Seattle              nurse   [traveling, trying new foods]   \n",
       "5         Boston             lawyer              [golfing, fishing]   \n",
       "6         Austin            student           [music, volunteering]   \n",
       "7            NYC         art expert                              []   \n",
       "\n",
       "   is_married  num_children  net_worth first_letter  \n",
       "0       False           1.0  1200000.0            A  \n",
       "1        True           2.0   500000.0            B  \n",
       "2        True           1.0   800000.0            C  \n",
       "3       False           NaN  1500000.0            D  \n",
       "4       False           NaN   400000.0            E  \n",
       "5        True           3.0        3.2            F  \n",
       "6       False           NaN        NaN            G  \n",
       "7       False           NaN        NaN            K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sculptor import Sculptor\n",
    "from sculptor import SculptorPipeline\n",
    "from helpers.data_sources import CSVDataSource\n",
    "\n",
    "# 1. Create our sculptors\n",
    "relevance_sculptor = Sculptor(\n",
    "    schema={\n",
    "        \"is_valid_sample\": {\"type\": bool, \"description\": \"True only if this text contains information about a person.\"},\n",
    "        \"explanation\": {\"type\": str, \"description\": \"Explain why this sample is or is not valid.\"}\n",
    "    },\n",
    "    instructions=\"Determine if the following text contains information about a person.\",\n",
    "    template=\"Text: {text}\"\n",
    ")\n",
    "\n",
    "demo_sculptor = Sculptor.from_config(\"examples/demosculpt.yaml\")\n",
    "demo_sculptor.add(\"first_letter\", str, \"First letter of the persons first name\")\n",
    "\n",
    "# 2. Create and configure the pipeline\n",
    "pipeline = (SculptorPipeline()\n",
    "    .add(relevance_sculptor, lambda x: x['is_valid_sample'])  # Filter on is_valid_sample\n",
    "    .add(demo_sculptor))\n",
    "\n",
    "# 3. Load and process the data\n",
    "csv_source = CSVDataSource(\"examples/people.csv\")\n",
    "df = csv_source.get_data()\n",
    "\n",
    "# 4. Run the pipeline (will preserve all columns by default)\n",
    "results = pipeline.process(\n",
    "    df.to_dict('records'),\n",
    "    n_workers=4,  # Parallel processing\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "# 5. Convert back to DataFrame\n",
    "extracted_df = pd.DataFrame(results)\n",
    "\n",
    "# Display results\n",
    "extracted_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test full AI Therapy Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import toml\n",
    "import praw\n",
    "import pandas as pd\n",
    "from sculptor import Sculptor\n",
    "from sculptor import SculptorPipeline\n",
    "from helpers.data_sources import RedditDataSource\n",
    "\n",
    "secrets = toml.load(\"secrets.toml\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = secrets[\"openai\"][\"api_key\"]\n",
    "os.environ[\"DEEPINFRA_API_KEY\"] = secrets[\"deepinfra\"][\"api_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "            client_id=secrets[\"reddit\"][\"client_id\"],\n",
    "            client_secret=secrets[\"reddit\"][\"client_secret\"],\n",
    "            user_agent=secrets[\"reddit\"][\"user_agent\"]\n",
    "        )\n",
    "\n",
    "reddit_src1 = RedditDataSource(\n",
    "    reddit_client=reddit,\n",
    "    query=\"(AI OR chatbot OR GPT) AND (mental health OR therapy)\",\n",
    "    include_comments=False,\n",
    "    limit=10\n",
    ")\n",
    "reddit_src2 = RedditDataSource(\n",
    "    reddit_client=reddit,\n",
    "    query=\"(AI OR chatbot OR GPT)\",\n",
    "    subreddits=[\"ADHD\", \"anxiety\"],\n",
    "    include_comments=False,\n",
    "    limit=10\n",
    ")\n",
    "\n",
    "dfs = [reddit_src1.get_data(), reddit_src2.get_data()]\n",
    "df = pd.concat(dfs, ignore_index=True).drop_duplicates(subset='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items: 100%|██████████| 20/20 [01:16<00:00,  3.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to 6 items\n",
      "\n",
      "Step 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items: 100%|██████████| 6/6 [00:55<00:00,  9.32s/it]\n"
     ]
    }
   ],
   "source": [
    "pipeline = SculptorPipeline.from_config('examples/ai_therapy.yaml')\n",
    "results = pipeline.process(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>context_text</th>\n",
       "      <th>url</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>is_comment</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>...</th>\n",
       "      <th>relevant_sample_explanation</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>benefits</th>\n",
       "      <th>downsides</th>\n",
       "      <th>use_cases</th>\n",
       "      <th>conditions</th>\n",
       "      <th>seeing_provider</th>\n",
       "      <th>previous_provider</th>\n",
       "      <th>provider_problems</th>\n",
       "      <th>analysis_notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1fajq7r_post</td>\n",
       "      <td>I've been desperately trying to figure out wha...</td>\n",
       "      <td>Chat GPT Transforms My Mental Health In 2 Weeks</td>\n",
       "      <td></td>\n",
       "      <td>https://reddit.com/r/ChatGPT/comments/1fajq7r/...</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>775</td>\n",
       "      <td>2024-09-06 16:40:03</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>The user explicitly describes their personal e...</td>\n",
       "      <td>9</td>\n",
       "      <td>[improved self-esteem, increased confidence, b...</td>\n",
       "      <td>[none mentioned]</td>\n",
       "      <td>[CBT, journaling, venting, goal setting]</td>\n",
       "      <td>[low self-esteem]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[slow progress]</td>\n",
       "      <td>The user credits Chat GPT with transforming th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1gmmujy_post</td>\n",
       "      <td>Hey!\\n\\nYou probably heard about people using ...</td>\n",
       "      <td>Using ChatGPT as a tool to improve your mental...</td>\n",
       "      <td></td>\n",
       "      <td>https://reddit.com/r/DecidingToBeBetter/commen...</td>\n",
       "      <td>DecidingToBeBetter</td>\n",
       "      <td>756</td>\n",
       "      <td>2024-11-08 16:40:52</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>The user explicitly describes their personal e...</td>\n",
       "      <td>9</td>\n",
       "      <td>[new perspectives, valuable advice, progress i...</td>\n",
       "      <td>[initial skepticism]</td>\n",
       "      <td>[venting, problem-solving]</td>\n",
       "      <td>[broken mind, being stuck]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[previous providers didn't work for the user]</td>\n",
       "      <td>The user is surprised by the effectiveness of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1bhxtuf_post</td>\n",
       "      <td>For me specifically, I am looking for somethin...</td>\n",
       "      <td>What are the best ai assistants or ai tools fo...</td>\n",
       "      <td></td>\n",
       "      <td>https://reddit.com/r/ADHD/comments/1bhxtuf/wha...</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>24</td>\n",
       "      <td>2024-03-18 18:23:40</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>The user shares a personal experience of strug...</td>\n",
       "      <td>8</td>\n",
       "      <td>[potential for improved executive functioning ...</td>\n",
       "      <td>[ineffective memory in chat GPT]</td>\n",
       "      <td>[personal assistant, task reminders, prioritiz...</td>\n",
       "      <td>[ADHD]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[none mentioned]</td>\n",
       "      <td>The user is seeking an AI assistant to support...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1hjkwj8_post</td>\n",
       "      <td>I feel like my RSD plays a huge role in my rel...</td>\n",
       "      <td>ChatGPT Hack</td>\n",
       "      <td></td>\n",
       "      <td>https://reddit.com/r/ADHD/comments/1hjkwj8/cha...</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>11</td>\n",
       "      <td>2024-12-21 22:31:38</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>The user explicitly describes their personal e...</td>\n",
       "      <td>9</td>\n",
       "      <td>[emotional regulation, safe space for venting,...</td>\n",
       "      <td>[none mentioned]</td>\n",
       "      <td>[venting, journaling, conflict resolution]</td>\n",
       "      <td>[ADHD, RSD (Rejection Sensitive Dysphoria)]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[none mentioned]</td>\n",
       "      <td>The user discovered a creative hack using Chat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1h2iv07_post</td>\n",
       "      <td>This is from a comment I made on some tech pos...</td>\n",
       "      <td>Using “AI” to organize my scatter Brain thoughts</td>\n",
       "      <td></td>\n",
       "      <td>https://reddit.com/r/ADHD/comments/1h2iv07/usi...</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-11-29 10:22:13</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>The user explicitly describes their personal e...</td>\n",
       "      <td>9</td>\n",
       "      <td>[Improved organization, Increased productivity...</td>\n",
       "      <td>[None mentioned]</td>\n",
       "      <td>[Organizing thoughts, Breaking down ideas into...</td>\n",
       "      <td>[ADHD]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[None mentioned]</td>\n",
       "      <td>The user utilizes chatGPT to manage their ADHD...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text  \\\n",
       "0  1fajq7r_post  I've been desperately trying to figure out wha...   \n",
       "1  1gmmujy_post  Hey!\\n\\nYou probably heard about people using ...   \n",
       "2  1bhxtuf_post  For me specifically, I am looking for somethin...   \n",
       "3  1hjkwj8_post  I feel like my RSD plays a huge role in my rel...   \n",
       "4  1h2iv07_post  This is from a comment I made on some tech pos...   \n",
       "\n",
       "                                               title context_text  \\\n",
       "0    Chat GPT Transforms My Mental Health In 2 Weeks                \n",
       "1  Using ChatGPT as a tool to improve your mental...                \n",
       "2  What are the best ai assistants or ai tools fo...                \n",
       "3                                       ChatGPT Hack                \n",
       "4   Using “AI” to organize my scatter Brain thoughts                \n",
       "\n",
       "                                                 url           subreddit  \\\n",
       "0  https://reddit.com/r/ChatGPT/comments/1fajq7r/...             ChatGPT   \n",
       "1  https://reddit.com/r/DecidingToBeBetter/commen...  DecidingToBeBetter   \n",
       "2  https://reddit.com/r/ADHD/comments/1bhxtuf/wha...                ADHD   \n",
       "3  https://reddit.com/r/ADHD/comments/1hjkwj8/cha...                ADHD   \n",
       "4  https://reddit.com/r/ADHD/comments/1h2iv07/usi...                ADHD   \n",
       "\n",
       "   score         created_utc  is_comment comment_id  ...  \\\n",
       "0    775 2024-09-06 16:40:03       False       None  ...   \n",
       "1    756 2024-11-08 16:40:52       False       None  ...   \n",
       "2     24 2024-03-18 18:23:40       False       None  ...   \n",
       "3     11 2024-12-21 22:31:38       False       None  ...   \n",
       "4      0 2024-11-29 10:22:13       False       None  ...   \n",
       "\n",
       "                         relevant_sample_explanation sentiment  \\\n",
       "0  The user explicitly describes their personal e...         9   \n",
       "1  The user explicitly describes their personal e...         9   \n",
       "2  The user shares a personal experience of strug...         8   \n",
       "3  The user explicitly describes their personal e...         9   \n",
       "4  The user explicitly describes their personal e...         9   \n",
       "\n",
       "                                            benefits  \\\n",
       "0  [improved self-esteem, increased confidence, b...   \n",
       "1  [new perspectives, valuable advice, progress i...   \n",
       "2  [potential for improved executive functioning ...   \n",
       "3  [emotional regulation, safe space for venting,...   \n",
       "4  [Improved organization, Increased productivity...   \n",
       "\n",
       "                          downsides  \\\n",
       "0                  [none mentioned]   \n",
       "1              [initial skepticism]   \n",
       "2  [ineffective memory in chat GPT]   \n",
       "3                  [none mentioned]   \n",
       "4                  [None mentioned]   \n",
       "\n",
       "                                           use_cases  \\\n",
       "0           [CBT, journaling, venting, goal setting]   \n",
       "1                         [venting, problem-solving]   \n",
       "2  [personal assistant, task reminders, prioritiz...   \n",
       "3         [venting, journaling, conflict resolution]   \n",
       "4  [Organizing thoughts, Breaking down ideas into...   \n",
       "\n",
       "                                    conditions seeing_provider  \\\n",
       "0                            [low self-esteem]           False   \n",
       "1                   [broken mind, being stuck]           False   \n",
       "2                                       [ADHD]           False   \n",
       "3  [ADHD, RSD (Rejection Sensitive Dysphoria)]           False   \n",
       "4                                       [ADHD]           False   \n",
       "\n",
       "   previous_provider                              provider_problems  \\\n",
       "0               True                                [slow progress]   \n",
       "1               True  [previous providers didn't work for the user]   \n",
       "2              False                               [none mentioned]   \n",
       "3              False                               [none mentioned]   \n",
       "4              False                               [None mentioned]   \n",
       "\n",
       "                                      analysis_notes  \n",
       "0  The user credits Chat GPT with transforming th...  \n",
       "1  The user is surprised by the effectiveness of ...  \n",
       "2  The user is seeking an AI assistant to support...  \n",
       "3  The user discovered a creative hack using Chat...  \n",
       "4  The user utilizes chatGPT to manage their ADHD...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_TAG = \"ai_therapy\"\n",
    "CONFIG_FILE = f\"configs/{CONFIG_TAG}.toml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toml\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from helpers.datasource import RedditDataSource, HackerNewsDataSource\n",
    "\n",
    "from helpers.processor import Processor, FILTER_PROMPT\n",
    "import helpers.visualizer as visualizer\n",
    "\n",
    "secrets = toml.load(\"secrets.toml\")\n",
    "config = toml.load(CONFIG_FILE)\n",
    "\n",
    "ANALYSIS_USE_CASE = config[\"use_case\"]\n",
    "FIELDS = config[\"fields\"]\n",
    "\n",
    "DEEPINFRA_CONFIG = secrets.get(\"deepinfra\", {})\n",
    "DEEPINFRA_LLM = OpenAI(\n",
    "  api_key=DEEPINFRA_CONFIG.get(\"api_key\"),\n",
    "  base_url=DEEPINFRA_CONFIG.get(\"base_url\"), \n",
    ")\n",
    "\n",
    "OPENAI_CONFIG = secrets.get(\"openai\", {})\n",
    "OPENAI_LLM = OpenAI(\n",
    "  api_key=OPENAI_CONFIG.get(\"api_key\"),\n",
    "  base_url=OPENAI_CONFIG.get(\"base_url\"), \n",
    ")\n",
    "\n",
    "processor = Processor(\n",
    "    use_case_description=ANALYSIS_USE_CASE,\n",
    "    filter_prompt=FILTER_PROMPT,\n",
    "    extraction_schema=FIELDS,\n",
    "    filter_llm_client=DEEPINFRA_LLM,\n",
    "    filter_model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",  # Cheaper model for filtering\n",
    "    extract_llm_client=DEEPINFRA_LLM,\n",
    "    extract_model=\"meta-llama/Meta-Llama-3.1-405B-Instruct\",  # More accurate model for extraction\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sources = []\n",
    "\n",
    "for ds_conf in config[\"data_sources\"]:\n",
    "    ds_type = ds_conf.pop(\"type\", None)\n",
    "    if ds_type == \"reddit\":\n",
    "        data_sources.append(RedditDataSource(**ds_conf))\n",
    "    elif ds_type == \"hackernews\":\n",
    "        data_sources.append(HackerNewsDataSource(**ds_conf))\n",
    "    else:\n",
    "        print(f\"Unknown data source type: {ds_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [source.get_data() for source in data_sources]\n",
    "df = pd.concat(dfs, ignore_index=True).drop_duplicates(subset='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_filtered = processor.filter_data(df.sample(n=100, random_state=42))  # For testing with a small random sample\n",
    "df_filtered = processor.filter_data(df)  # 1st level filtering\n",
    "df_extracted = processor.extract_fields(df_filtered)  # Extraction of structured data\n",
    "samples = df_extracted[df_extracted['relevant_sample'] == True]  # 2nd level filtering\n",
    "print(f\"Samples: initial={len(df)}, after 1st filter={len(df_filtered[df_filtered['is_relevant']==True])}, final={len(samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Backup dataframes to output files\n",
    "# df.to_json(f\"out/{CONFIG_TAG}.json\", orient='records', date_format='iso')\n",
    "# df_filtered.to_json(f\"out/{CONFIG_TAG}-filtered.json\", orient='records', date_format='iso') \n",
    "# samples.to_json(f\"out/{CONFIG_TAG}-samples.json\", orient='records', date_format='iso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple plots are created automatically by vizualizer\n",
    "viz = visualizer.Visualization(samples, FIELDS)\n",
    "viz.plot_all_fields(show_examples=True)\n",
    "viz.show_samples(n=3, extra_fields=['sentiment','use_cases'])\n",
    "viz.plot_by_time('created_utc', \"Posts Over Time\")\n",
    "# viz.plot_group_comparison('subreddit', 'sentiment', agg='mean')\n",
    "# viz.plot_correlation(['sentiment'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
